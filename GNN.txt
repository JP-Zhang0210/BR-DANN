import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATConv, global_mean_pool, global_max_pool
from torch_geometric.data import Data, Batch

class AntennaGNNFeatureExtractor(nn.Module):

    
    def __init__(self, 
                 node_input_dim=5,  # [x, y, z, amplitude, phase]
                 edge_input_dim=4,  # [dx, dy, dz, distance]
                 hidden_dim=128,
                 num_layers=4,
                 num_heads=8,
                 dropout=0.1):
        super(AntennaGNNFeatureExtractor, self).__init__()
        
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.dropout = dropout
        
     
        self.node_encoder = nn.Sequential(
            nn.Linear(node_input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.LeakyReLU(0.2),
            nn.Dropout(dropout)
        )
        
       
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.LeakyReLU(0.2),
            nn.Dropout(dropout)
        )
        
        
        self.gnn_layers = nn.ModuleList()
        for i in range(num_layers):
            
            conv_layer = GATConv(
                hidden_dim, 
                hidden_dim // num_heads,
                heads=num_heads,
                dropout=dropout,
                edge_dim=hidden_dim,  # 边特征维度
                add_self_loops=True
            )
            self.gnn_layers.append(conv_layer)
        
     
        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(hidden_dim) for _ in range(num_layers)
        ])
        
        
        self.update_gates = nn.ModuleList([
            nn.Sequential(
                nn.Linear(hidden_dim * 2, hidden_dim),
                nn.Sigmoid()
            ) for _ in range(num_layers)
        ])
        
        
        self.output_proj = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.LeakyReLU(0.2),
            nn.Dropout(dropout)
        )

    def forward(self, data):
       
        
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch
        
        
        h = self.node_encoder(x)  # [num_nodes, hidden_dim]
        edge_emb = self.edge_encoder(edge_attr)  # [num_edges, hidden_dim]
        
        
        for i, (conv, norm, gate) in enumerate(zip(self.gnn_layers, self.layer_norms, self.update_gates)):
            
            
            h_prev = h
            
            
            h_new = conv(h, edge_index, edge_emb)  # [num_nodes, hidden_dim]
            h_new = norm(h_new)
            h_new = F.leaky_relu(h_new, 0.2)
            h_new = F.dropout(h_new, p=self.dropout, training=self.training)
            
            
            gate_input = torch.cat([h_prev, h_new], dim=-1)  # [num_nodes, 2*hidden_dim]
            update_gate = gate(gate_input)  # [num_nodes, hidden_dim]
            
            
            h = update_gate * h_new + (1 - update_gate) * h_prev
        
        
        node_features = self.output_proj(h)  # [num_nodes, hidden_dim]
        
        
        graph_features = self.attention_pooling(node_features, batch)  # [batch_size, hidden_dim]
        
        return node_features, graph_features
    
    def attention_pooling(self, node_features, batch):
        
        attention_weights = torch.tanh(self.attention_proj(node_features))  # [num_nodes, 1]
        attention_weights = torch.sigmoid(attention_weights)
        
        
        graph_features = []
        for graph_id in torch.unique(batch):
            mask = (batch == graph_id)
            graph_node_features = node_features[mask]
            graph_attention_weights = attention_weights[mask]
            
            
            weighted_features = graph_node_features * graph_attention_weights
            graph_feature = weighted_features.sum(dim=0) / graph_attention_weights.sum()
            graph_features.append(graph_feature)
        
        return torch.stack(graph_features)  # [batch_size, hidden_dim]

    def init_attention_pooling(self, hidden_dim):
        
        self.attention_proj = nn.Linear(hidden_dim, 1)
        nn.init.xavier_uniform_(self.attention_proj.weight)
        nn.init.constant_(self.attention_proj.bias, 0)


class ArrayGraphBuilder:
    
    
    def __init__(self, k_neighbors=8, use_self_loops=True):
        self.k_neighbors = k_neighbors
        self.use_self_loops = use_loops
    
    def build_graph_from_array(self, positions, excitations, wavelength=1.0):
     
        num_elements = positions.shape[0]
        
        
        node_features = torch.zeros(num_elements, 5)
        node_features[:, :3] = positions / wavelength  
        node_features[:, 3] = excitations[:, 0]  
        node_features[:, 4] = excitations[:, 1]  
        
        
        edge_index, edge_attributes = self._build_knn_graph(positions, wavelength)
        
        return Data(
            x=node_features,
            edge_index=edge_index,
            edge_attr=edge_attributes
        )
    
    def _build_knn_graph(self, positions, wavelength):
        
        from torch_cluster import knn_graph
        
        
        edge_index = knn_graph(positions, k=self.k_neighbors, batch=None, loop=self.use_self_loops)
        
        
        src_nodes = edge_index[0]
        dst_nodes = edge_index[1]
        
        src_pos = positions[src_nodes]
        dst_pos = positions[dst_nodes]
        
        
        delta_pos = dst_pos - src_pos
        distances = torch.norm(delta_pos, dim=1, keepdim=True)
        
        
        edge_attributes = torch.cat([
            delta_pos / wavelength,  
            distances / wavelength   
        ], dim=1)
        
        return edge_index, edge_attributes



if __name__ == "__main__":
    
    graph_builder = ArrayGraphBuilder(k_neighbors=8)
    
    
    num_elements = 100
    positions = torch.randn(num_elements, 3)  
    excitations = torch.randn(num_elements, 2)  
    
    
    graph_data = graph_builder.build_graph_from_array(positions, excitations)
    
    
    gnn_extractor = AntennaGNNFeatureExtractor(
        node_input_dim=5,
        edge_input_dim=4,
        hidden_dim=128,
        num_layers=4,
        num_heads=8
    )
    
    
    node_features, graph_features = gnn_extractor(graph_data)
    
    